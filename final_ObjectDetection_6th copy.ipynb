{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\atharva\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\atharva\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\atharva\\anaconda3\\lib\\site-packages (from tensorflow-hub) (1.26.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\atharva\\anaconda3\\lib\\site-packages (from tensorflow-hub) (4.25.0)\n",
      "Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 85.4/85.4 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IdE6hPgKCZzn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atharva\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7lE48QiIC_cl"
   },
   "outputs": [],
   "source": [
    "Image_Shape = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hqXwzZm9DDZI"
   },
   "outputs": [],
   "source": [
    "URL_dataset = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UV0dS1jqDZm8",
    "outputId": "8f67e753-ee7e-48bc-f6e4-afafc4314c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228813984/228813984 [==============================] - 39s 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_dir = tf.keras.utils.get_file(origin = URL_dataset, fname='flower_photos' ,untar= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "QHz60UtjEPAm",
    "outputId": "1aa06784-f42b-4f12-f1c0-d07e3edcbc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "q1fVm2LkOCFt",
    "outputId": "10eb9eff-aed7-40a5-9a30-35fa688c5d61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_dir = pathlib.Path(data_dir)\\nfile_list = list(data_dir.glob('*/*.jpg'))\\nhalf_file_list = file_list[:len(file_list) // 2]\\n#image_count = len(list(data_dir.glob('*/*.jpg')))\\nimage_count = len(half_file_list)\\nprint(image_count)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_dir = pathlib.Path(data_dir)\n",
    "file_list = list(data_dir.glob('*/*.jpg'))\n",
    "half_file_list = file_list[:len(file_list) // 2]\n",
    "#image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count = len(half_file_list)\n",
    "print(image_count)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tb_OdpdBEpYk"
   },
   "outputs": [],
   "source": [
    "flowers_images_dict = {\"daisy\" : list(data_dir.glob('daisy/*')),\n",
    "                      \"dandelion\" : list(data_dir.glob('dandelion/*')),\n",
    "                      \"roses\" : list(data_dir.glob('roses/*')),\n",
    "                      \"sunflowers\" : list(data_dir.glob('sunflowers/*')),\n",
    "                      \"tulips\" : list(data_dir.glob('tulips/*'))}\n",
    "\n",
    "flowers_labels_dict = {\"daisy\" : 0,\n",
    "                       \"dandelion\" : 1,\n",
    "                       \"roses\" : 2,\n",
    "                       \"sunflowers\" : 3,\n",
    "                       \"tulips\" : 4}\n",
    "\n",
    "X, Y = [],[]\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "  for image in images:\n",
    "    img = cv2.imread(str(image))\n",
    "    resized_img = cv2.resize(img, Image_Shape)\n",
    "    X.append(resized_img)\n",
    "    Y.append(flowers_labels_dict[flower_name])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jdalRzLXG2P5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h5yam13cHOi4"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=0)\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fqndgb0sHuuY"
   },
   "outputs": [],
   "source": [
    "tf_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VHU3LivvIAbX"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.Sequential([hub.KerasLayer(tf_model, input_shape = (224,224,3), trainable=False),\n",
    "tf.keras.layers.Dense(len(flowers_labels_dict), activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "JcWb8kXaJaja",
    "outputId": "9c9670b5-3d2a-4744-dcde-d4a489f60c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2264389 (8.64 MB)\n",
      "Trainable params: 6405 (25.02 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()\n",
    "classifier.compile(optimizer=\"adam\",\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "y3-b9LrzN5RN",
    "outputId": "4e21b5ce-f7cd-4f59-9730-9a646c3bfe6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atharva\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 15s 415ms/step - loss: 1.2693 - accuracy: 0.5087\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 12s 411ms/step - loss: 0.6344 - accuracy: 0.7745\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.4621 - accuracy: 0.8464\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.3753 - accuracy: 0.8922\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 11s 370ms/step - loss: 0.3137 - accuracy: 0.9172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d4ade92fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_test_scaled, Y_test, epochs = 5)\n",
    "#classifier.evaluate(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "AgWznt92SKHx",
    "outputId": "a847d396-62b0-49d5-e1fd-80c43c714740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 11s 364ms/step - loss: 0.2787 - accuracy: 0.9303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2786589562892914, 0.93028324842453]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "xqMCvZclSLHH",
    "outputId": "208785f2-f1af-434f-f17c-f4c974969733"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/content/11746080_963537acdc.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19312\\235915404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Open the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3091\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3092\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3093\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/content/11746080_963537acdc.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the relative path to the image file\n",
    "image_path = os.path.join(current_directory, \"/content/11746080_963537acdc.jpg\")\n",
    "\n",
    "# Open the image\n",
    "img = Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RZaFJpwZUBd2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported image shape: ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19312\\4067152130.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage_Shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\image_utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Unsupported image shape: {x.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported image shape: ()"
     ]
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.img_to_array(img.resize(Image_Shape))\n",
    "img = np.array([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "L80ZLRXcXE3W",
    "outputId": "6ac97fee-1a8b-4606-d40e-4d91e5423451"
   },
   "outputs": [],
   "source": [
    "res = classifier.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4Nq43i04XJrX",
    "outputId": "ec0d8062-a06b-49c3-efa7-f0452d434c11"
   },
   "outputs": [],
   "source": [
    "print(\"The prediction is : {}\".format(list(flowers_labels_dict.keys())[np.argmax(res)]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
