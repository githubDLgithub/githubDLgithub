{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing Feedforward neural networks with Keras and TensorFlow**\n",
        "##**a. Import the necessary packages**\n",
        "##**b. Load the training and testing data (MNIST/CIFAR10)**\n",
        "##**c. Define the network architecture using Keras**\n",
        "##**d. Train the model using SGD**\n",
        "##**e. Evaluate the network**\n",
        "##**f. Plot the training loss and accuracy**"
      ],
      "metadata": {
        "id": "xVbVp6barUzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**a. Importing Libraries**"
      ],
      "metadata": {
        "id": "LoYwuLyLj6Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "Us0ot_fKDrey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**b. Loading MNIST Dataset**"
      ],
      "metadata": {
        "id": "RK3gkIR2kH00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "6PaysH91E_db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()"
      ],
      "metadata": {
        "id": "20fMdtEeFoC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_mnist.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Hh6OrQF1qc",
        "outputId": "fbd10b97-8e50-4a9a-fdf3-4a4d12e74910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_mnist.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2sIDKFrS1Bc",
        "outputId": "83be6f55-97d9-482b-a725-127db8da1c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**c. Define the network architecture using Keras**"
      ],
      "metadata": {
        "id": "vK0il0TckQ4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaiVwykwS7Uo",
        "outputId": "8c69f291-5a22-4cdc-92d4-c7b6902c9eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Train the model using SGD**"
      ],
      "metadata": {
        "id": "vQexT4SKkVFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train_mnist, y_train_mnist, epochs=10, validation_data=(x_test_mnist, y_test_mnist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "7JvkuI0-S9Wa",
        "outputId": "240c6d73-4854-4f2f-9e8f-5f2baa4a1128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-288a0fdb6f47>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3952\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3954\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3955\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3956\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Evaluate the model**"
      ],
      "metadata": {
        "id": "ARekBhP3kZze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test_mnist, y_test_mnist)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "f4JvVLVEVfR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 20\n",
        "plt.imshow(x_test_mnist[n])\n",
        "predicted_value = model.predict(x_test_mnist)\n",
        "print(\"Predicted Number: \", np.argmax(predicted_value[n]))"
      ],
      "metadata": {
        "id": "RS4WgueJDrEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**f. Plot the training loss and accuracy**"
      ],
      "metadata": {
        "id": "GFqBYIBvkd0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NdPBdy-SVhSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nM475ZqqW6ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This section imports necessary libraries:\n",
        "# numpy for numerical operations.\n",
        "# pandas for data manipulation and analysis.\n",
        "# matplotlib and seaborn for data visualization.\n",
        "# tensorflow for building and training deep learning models.\n",
        "# Sequential, Dense, Dropout, and Flatten are specific components from TensorFlow's Keras API that will be used to build a neural network.\n",
        "\n",
        "# Sequential is a linear stack of layers in a neural network model. It is a simple and straightforward way to build a neural network model, layer by layer, where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "# Dense is a fully connected layer in a neural network. In a dense layer, each neuron (or node) is connected to every neuron in the previous layer, and each connection has a weight associated with it. The output from the dense layer is calculated by applying an activation function to the weighted sum of the inputs.\n",
        "\n",
        "# Dropout is a regularization technique used to prevent overfitting in neural networks. During training, a fraction of randomly selected neurons are \"dropped out,\" meaning their outputs are set to zero\n",
        "\n",
        "#  is a layer used to convert multidimensional data into a one-dimensional array. In the context of image data,"
      ],
      "metadata": {
        "id": "tF7dIVgFANZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line defines the MNIST dataset using TensorFlow's Keras datasets. MNIST is a dataset of 28x28 images of handwritten digits (0 through 9)."
      ],
      "metadata": {
        "id": "Kw2NOr5GAXAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line loads the MNIST dataset into training and testing sets, with images (x_train_mnist and x_test_mnist) and corresponding labels (y_train_mnist and y_test_mnist)."
      ],
      "metadata": {
        "id": "DqcVRqNZAcS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These lines define a simple neural network model using Keras:\n",
        "# Sequential() initializes an empty model.\n",
        "# Flatten(input_shape=(28, 28)) flattens the 28x28 input images into a 1D array.\n",
        "# Dense(128, activation='relu') adds a fully connected layer with 128 neurons and ReLU activation.\n",
        "# Dropout(0.2) adds a dropout layer with a dropout rate of 0.2 to prevent overfitting.\n",
        "# Dense(10, activation='softmax') adds the output layer with 10 neurons (for digits 0-9) using softmax activation.\n",
        "# compile configures the model for training with the Adam optimizer, sparse categorical crossentropy loss, and accuracy as the metric.\n",
        "# summary() prints a summary of the model architecture.\n"
      ],
      "metadata": {
        "id": "F2hXFDk4Arxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line trains the model on the MNIST training data for 10 epochs, using the validation data for monitoring performance during training. The training history is stored in the history variable."
      ],
      "metadata": {
        "id": "vWaxrbtqC9mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU, or Rectified Linear Unit, is a widely used activation function in neural networks. It introduces non-linearity by outputting the input for positive values and zero for negative values.\n",
        "\n",
        "# Softmax is an activation function often used in the output layer of a neural network for multi-class classification problems. It transforms raw output scores into probabilities, ensuring that the sum of the probabilities for all classes is equal to one. Softmax is especially useful when the network needs to make mutually exclusive predictions, assigning high probabilities to the most likely class."
      ],
      "metadata": {
        "id": "rLkym7jIDA_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam, short for Adaptive Moment Estimation, is an optimization algorithm commonly used in training deep neural networks. It combines the benefits of both momentum and RMSprop methods, maintaining moving averages of the gradients and squared gradients. Adam adapts the learning rates for each parameter individually, providing efficient and effective convergence by adjusting the step size based on the historical information of gradients.\n",
        "\n",
        "# Sparse Categorical Crossentropy is a loss function employed in classification tasks where each input belongs to one class out of multiple classes."
      ],
      "metadata": {
        "id": "9wWmIPxvDQ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7rCMRRIDUAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}